# zephyr-7B-beta-GGUF-infrence-on-collab
This repo. contains a rag-on pdf file using the quantized GGUF model of Zephyr beta.

## Original repo by huggingfaceh4 [TheBloke/zephyr-7B-beta ](https://huggingface.co/HuggingFaceH4/zephyr-7b-beta)
## Quantized repo by TheBloke [TheBloke/zephyr-7B-beta-GGUF](https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/tree/main)


### Results 

* Even though it is a quantized model, infrence on the colab CPU takes a few minutes.
* Results are fine.

## Thank you [Ai Anytime](https://github.com/AIAnytime)  for the zeypher cpu infrence video.
---
Connect with me for more projects like this ðŸ˜Š:

## Github: [Github](https://github.com/sibap865)
## LinkedIn: [My profile](https://www.linkedin.com/in/sibaprasad-naik-behera-98043b1ba/)